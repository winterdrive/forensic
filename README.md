# 📊 2025 資料科學組競賽 - 分類器訓練方法說明

## 🎯 專案概述

本專案針對 2025 資料科學組競賽開發了一套混合式分類系統，用於判斷簡訊是否：

1. **屬於「旅遊行程與服務通知」類別** → `label = 1`
2. **含有中文姓名** → `name_flg = 1`

我們採用了 **LLM 標註 + BERT 訓練** 的混合策略，結合多個模型的優勢來提升分類準確度。

---

## 🏗️ 整體架構

### 📊 數據流程圖

```text
原始數據 (200,000+ SMS)
      ↓
[LLM 標註階段] - 使用多個LLM進行初步分類
      ↓
[人工校驗] - 處理模型間歧異，確保標註品質
      ↓
[數據整合] - 整合為 8,000 筆高品質訓練數據
      ↓
[BERT 訓練] - 訓練多個BERT變體模型
      ↓
[模型融合] - 投票決策與歧異檢測
      ↓
最終預測結果
```

---

## 📝 資料標註流程

### 第一階段：LLM 多模型標註

我們選用了表現優異的三個 LLM 模型進行初步標註：

#### 🤖 使用的 LLM 模型

- **Gemini 2.5 Flash** (Google)
- **Llama-3.3-70B-Instruct** (Meta)
- **DeepSeek-R1-Distill-Llama-70B** (DeepSeek)
- **Magistral-Small-2506** (Mistral AI)

#### 📋 標註策略

1. **結構化提示詞設計**：
   - 姓名分類：明確定義中文姓名的識別規則，包含標準姓名、暱稱小名、稱謂用法等
   - 旅遊分類：聚焦於旅遊行程通知、旅行社發送、相關關鍵字等判斷依據

2. **XML 格式化輸入**：
   - 使用 XML 結構化輸入簡訊內容，提升 LLM 解析準確度
   - 實作 XML 轉義處理，避免特殊字元影響解析

3. **批次處理優化**：
   - 每次處理 20-50 則簡訊，平衡效率與準確度
   - 實作 token 數量估算，控制 API 呼叫成本

### 第二階段：人工校驗與品質控制

#### 🔍 歧異檢測機制

- **三模型投票制**：當任一模型預測結果與其他不同時，標記為需人工檢查
- **共識決策**：只有當模型間達成共識的預測才自動採納
- **分歧處理**：所有分歧案例都經過人工逐一檢視和標註

#### 📊 品質檢查流程

1. **mismatch 識別**：使用 `majority_vote.py` 腳本自動識別模型間分歧
2. **Google Sheets 協作**：建立線上表單供團隊成員協作標註
3. **交叉驗證**：重要案例由多人獨立標註後討論確認

### 第三階段：數據集構建

#### 📚 訓練數據來源

最終的訓練集 (`train_8000.csv`) 整合了以下數據源：

1. **官方提供數據** (1,000 筆)：
   - `both_6_offical.csv` - 6 筆
   - `name_1000_offical.csv` - 994 筆姓名標註
   - `travel_1000_offical.csv` - 994 筆旅遊標註

2. **第一輪人工標註** (3,000 筆)：
   - `raw_3000_labeled.csv` - 經過多 LLM 投票和人工校驗

3. **擴充標註數據** (4,000 筆)：
   - `name_consensus.csv` / `travel_consensus.csv` - 額外擴充的高品質標註

#### 🔧 數據預處理 (`train_8000.py`)

1. **ID 標準化**：排序、去重、去除空值
2. **標籤整合**：合併來自不同來源的標註結果
3. **品質驗證**：確保所有標籤為 0/1 二元值，無缺失值
4. **數據分割**：按 8:1:1 比例分割為訓練/驗證/測試集

---

## 🤖 BERT 模型訓練

### 模型選擇策略

我們訓練了多個 BERT 變體，針對中文文本特性進行優化：

#### 🏆 主要模型架構

1. **distilbert-base-multilingual-cased**
   - 多語言支持，適合處理中英混合簡訊
   - 輕量化設計，推論速度快
   - 配置：學習率 2e-5，批次大小 16

2. **hfl/chinese-macbert-large**
   - 專為中文設計的大型模型
   - 更強的中文語義理解能力
   - 配置：學習率 1e-5，批次大小 8（記憶體限制）

3. **ckiplab/bert-base-chinese**
   - 中研院開發的中文 BERT
   - 在中文任務上表現優異
   - 平衡效能與準確度

### 🛠️ 訓練配置

#### 共同訓練參數

```ini
max_length = 512          # 最大序列長度
num_epochs = 5            # 訓練輪數
warmup_steps = 500        # 預熱步數
weight_decay = 0.01       # 權重衰減
early_stopping_patience = 3  # 早停機制
random_seed = 42          # 隨機種子
```

#### 分別訓練策略

- **姓名分類器** (`bert_name_trainer.py`)：專注於識別中文姓名模式
- **旅遊分類器** (`bert_travel_trainer.py`)：專注於旅遊相關語義理解

### 📊 訓練監控

#### Weights & Biases 整合

- 實時監控訓練 loss 和驗證準確率
- 自動保存最佳模型權重
- 訓練過程可視化和分析

#### 評估指標

- **準確率 (Accuracy)**
- **精確率 (Precision)**
- **召回率 (Recall)**
- **F1 Score**
- **AUC-ROC**

---

## 🔄 推論與融合策略

### 多模型推論

#### LLM 推論 (`llm_*_classifier.py`)

- 結構化 XML 輸入處理
- 批次推論優化
- API 失敗重試機制
- 結果格式標準化

#### BERT 推論 (`bert_*_inference.py`)

- GPU 加速推論
- 批次處理優化
- 機率輸出與閾值調整
- 模型權重自動載入

### 🗳️ 投票融合機制

#### 共識決策 (`majority_vote.py`)

1. **多模型預測整合**：收集所有模型的預測結果
2. **歧異檢測**：標記模型間預測不一致的案例
3. **人工介入**：對歧異案例進行人工審查和修正
4. **最終決策**：結合模型共識和人工校正的最終結果

#### 上傳策略

- **第一次上傳**：使用 train_8000 訓練的模型結果
- **後續上傳**：
  - 添加 train_9000 擴充數據訓練的模型
  - 加入 MacBERT Large 增強預測能力
  - 根據排名變化動態調整策略

---

## 📈 實驗結果與優化

### 模型表現對比

基於會議記錄和實驗結果：

#### 訓練數據迭代

- **train_8000**：初版訓練集，建立基準表現
- **train_9000**：加入 mismatch 重新標註數據，提升模型穩健性

#### 模型評估結果

- **姓名分類**：目標準確率 >98%，如未達標考慮 NER 模型
- **旅遊分類**：通過多輪測試和人工驗證優化

### 🔧 持續優化策略

1. **歧異處理**：
   - 預賽：檢查所有 mismatch 案例
   - 正賽：對超過 30,000 筆的預測進行 mismatch 檢查和人工修正

2. **數據清理**：
   - 姓名分類：過濾掉所有 ○ 和 ＊ 符號
   - 確保最終上傳數據不超過 30,000 筆限制

3. **模型選擇**：
   - 根據驗證結果動態選擇最佳模型組合
   - 保持多個備選方案應對不同測試場景

---

## 🛠️ 技術實現細節

### 核心模組架構

#### 數據處理模組 (`src/pretreat/`)

- `train_8000.py`：數據集構建與標準化
- `majority_vote.py`：多模型投票與共識決策
- `llm_compare.py`：LLM 模型效能比較

#### 模型訓練模組 (`src/bert_model/`)

- `bert_*_trainer.py`：BERT 模型訓練腳本
- `bert_*_inference.py`：推論執行腳本
- `config*.ini`：模型配置檔案

#### LLM 分類模組 (`src/`)

- `llm_name_classifier.py`：LLM 姓名分類器
- `llm_travel_classifier.py`：LLM 旅遊分類器
- `utils.py`：共用工具函數

### 🔧 工程化特性

1. **模組化設計**：各功能獨立封裝，便於維護和測試
2. **配置驅動**：使用 INI 檔案管理模型參數和路徑
3. **錯誤處理**：完整的異常處理和重試機制
4. **日誌記錄**：詳細的訓練和推論過程記錄
5. **版本控制**：模型權重和結果檔案自動版本標記

---

## 🚀 部署與使用

### 環境需求

```bash
# 核心依賴
torch >= 1.9.0
transformers >= 4.20.0
pandas >= 1.3.0
scikit-learn >= 1.0.0

# 可選依賴
wandb  # 訓練監控
openai  # LLM API 調用
requests  # HTTP 請求處理
```

### 快速開始

1. **環境設置**：

   ```bash
   pip install -r requirements_bert.txt
   ```

2. **模型訓練**：

   ```bash
   # 訓練姓名分類器
   python src/bert_model/bert_name_trainer.py
   
   # 訓練旅遊分類器
   python src/bert_model/bert_travel_trainer.py
   ```

3. **模型推論**：

   ```bash
   # BERT 推論
   python src/bert_model/run_inference_simple.py
   
   # LLM 推論
   python src/llm_name_classifier.py
   ```

4. **結果融合**：

   ```bash
   python src/pretreat/majority_vote.py --input_dir results/
   ```

---

