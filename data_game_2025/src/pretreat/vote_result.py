"""
å¤šæ¨¡å‹åˆ†é¡çµæœåŠ æ¬Šæ•´åˆèˆ‡æ­£é¡æ’åºæ©Ÿåˆ¶

æœ¬è…³æœ¬ç”¨ä¾†å°ä½¿ç”¨è€…åœ¨æŒ‡å®šç›®éŒ„ data_game_2025/data/results/vote/candidates ä¸‹ï¼Œ
æ”¾ç½®çš„æ‰€æœ‰æª”æ¡ˆé€²è¡Œæ©Ÿç‡çš„åŠ æ¬Šå¹³å‡è¨ˆç®—ã€‚

æ ¹æ“šç«¶è³½è¦å‰‡ï¼Œåˆ†åˆ¥é¸å‡ºæ—…éŠåˆ†é¡å’Œå§“ååˆ†é¡æ©Ÿç‡æœ€é«˜çš„å‰ 30,000 ç­†æ­£é¡é æ¸¬ï¼Œ
ä½œç‚ºæœ¬æ¬¡ç«¶è³½çš„æäº¤çµæœã€‚

input_csv æª”æ¡ˆçš„æ ¼å¼ç‚ºï¼š
| æ¬„ä½ | èªªæ˜ |
|------|------|
| `sms_id` | ç°¡è¨Š ID |
| `travel_prob` | æ—…éŠåˆ†é¡é æ¸¬æ©Ÿç‡ |
| `label` | æ—…éŠåˆ†é¡é æ¸¬çµæœï¼ˆ0: éæ—…éŠ, 1: æ—…éŠï¼‰|
| `name_prob` | å§“ååˆ†é¡é æ¸¬æ©Ÿç‡ |
| `name_flg` | å§“ååˆ†é¡é æ¸¬çµæœï¼ˆ0: éå§“å, 1: å§“åï¼‰|

output_csv æª”æ¡ˆæœƒç”¢ç”Ÿå…©å€‹ï¼š
1. category_result.csv - æ—…éŠåˆ†é¡å‰30,000ç­†æ­£é¡ sms_id
2. name_result.csv - å§“ååˆ†é¡å‰30,000ç­†æ­£é¡ sms_id
"""

import pandas as pd
import numpy as np
import configparser
from pathlib import Path
import logging
from typing import List

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class VoteEnsemble:
    """å¤šæ¨¡å‹æŠ•ç¥¨é›†æˆé¡åˆ¥"""

    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–æŠ•ç¥¨é›†æˆå™¨

        Args:
            config_path: é…ç½®æª”æ¡ˆè·¯å¾‘ï¼Œé è¨­ç‚ºç›¸å°è·¯å¾‘
        """
        if config_path is None:
            # æ ¹æ“šç•¶å‰æª”æ¡ˆä½ç½®è¨ˆç®—ç›¸å°è·¯å¾‘
            current_dir = Path(__file__).parent
            config_path = current_dir / "../../bert_model/config.ini"

        self.config = configparser.ConfigParser()
        self.config.read(config_path)

        # å¾ config è®€å–è¨­å®š
        self.model_weights = eval(
            self.config.get("ensemble", "model_weights", fallback="[1, 1, 1]")
        )
        self.voting_strategy = self.config.get(
            "ensemble", "voting_strategy", fallback="weighted_average"
        )
        self.confidence_threshold = float(
            self.config.get("ensemble", "confidence_threshold", fallback="0.5")
        )

        # è¨­å®šè·¯å¾‘ - ä½¿ç”¨çµ•å°è·¯å¾‘ç¢ºä¿æº–ç¢ºæ€§
        self.candidates_dir = Path(
            "/Users/winstontang/PycharmProjects/forensic/data_game_2025/data/results/vote/candidates"
        )
        self.output_dir = Path(
            "/Users/winstontang/PycharmProjects/forensic/data_game_2025/data/results/vote/output"
        )

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"åˆå§‹åŒ–å®Œæˆ - æ¨¡å‹æ¬Šé‡: {self.model_weights}")
        logger.info(f"å€™é¸æª”æ¡ˆç›®éŒ„: {self.candidates_dir}")
        logger.info(f"è¼¸å‡ºç›®éŒ„: {self.output_dir}")

    def load_candidate_files(self) -> List[pd.DataFrame]:
        """è¼‰å…¥å€™é¸ç›®éŒ„ä¸‹çš„æ‰€æœ‰ CSV æª”æ¡ˆ"""
        csv_files = list(self.candidates_dir.glob("*.csv"))

        if not csv_files:
            raise FileNotFoundError(f"åœ¨ {self.candidates_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• CSV æª”æ¡ˆ")

        logger.info(f"æ‰¾åˆ° {len(csv_files)} å€‹å€™é¸æª”æ¡ˆ")

        dataframes = []
        for file_path in csv_files:
            logger.info(f"è¼‰å…¥æª”æ¡ˆ: {file_path.name}")
            df = pd.read_csv(file_path)

            # æª¢æŸ¥å¿…è¦æ¬„ä½
            required_columns = ["sms_id", "travel_prob", "name_prob"]
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                raise ValueError(
                    f"æª”æ¡ˆ {file_path.name} ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}"
                )

            dataframes.append(df)

        return dataframes

    def validate_consistency(self, dataframes: List[pd.DataFrame]) -> None:
        """é©—è­‰æ‰€æœ‰æ¨¡å‹çš„ sms_id æ˜¯å¦ä¸€è‡´"""
        if len(dataframes) < 2:
            logger.warning("åªæœ‰ä¸€å€‹æ¨¡å‹æª”æ¡ˆï¼Œç„¡éœ€é©—è­‰ä¸€è‡´æ€§")
            return

        reference_ids = set(dataframes[0]["sms_id"])

        for i, df in enumerate(dataframes[1:], 1):
            current_ids = set(df["sms_id"])
            if reference_ids != current_ids:
                missing_in_current = reference_ids - current_ids
                extra_in_current = current_ids - reference_ids

                error_msg = f"æ¨¡å‹ {i+1} çš„ sms_id èˆ‡ç¬¬ä¸€å€‹æ¨¡å‹ä¸ä¸€è‡´\n"
                if missing_in_current:
                    error_msg += f"ç¼ºå°‘çš„ ID: {list(missing_in_current)[:10]}...\n"
                if extra_in_current:
                    error_msg += f"å¤šé¤˜çš„ ID: {list(extra_in_current)[:10]}...\n"

                raise ValueError(error_msg)

        logger.info("æ‰€æœ‰æ¨¡å‹çš„ sms_id ä¸€è‡´æ€§é©—è­‰é€šé")

    def weighted_average(self, dataframes: List[pd.DataFrame]) -> pd.DataFrame:
        """è¨ˆç®—åŠ æ¬Šå¹³å‡"""
        if len(dataframes) == 1:
            logger.info("åªæœ‰ä¸€å€‹æ¨¡å‹ï¼Œç›´æ¥ä½¿ç”¨è©²æ¨¡å‹çµæœ")
            return dataframes[0].copy()

        # èª¿æ•´æ¬Šé‡æ•¸é‡ä»¥åŒ¹é…æ¨¡å‹æ•¸é‡
        weights = self.model_weights[: len(dataframes)]
        if len(weights) < len(dataframes):
            weights.extend([1] * (len(dataframes) - len(weights)))

        # æ­£è¦åŒ–æ¬Šé‡
        weights = np.array(weights)
        weights = weights / weights.sum()

        logger.info(f"ä½¿ç”¨æ¬Šé‡: {weights}")

        # åŸºæ–¼ç¬¬ä¸€å€‹ dataframe å»ºç«‹çµæœ
        result_df = dataframes[0][["sms_id"]].copy()

        # è¨ˆç®—åŠ æ¬Šå¹³å‡
        travel_probs = np.zeros(len(result_df))
        name_probs = np.zeros(len(result_df))

        for i, (df, weight) in enumerate(zip(dataframes, weights)):
            # ç¢ºä¿é †åºä¸€è‡´
            df_sorted = df.set_index("sms_id").loc[result_df["sms_id"]].reset_index()

            travel_probs += df_sorted["travel_prob"].values * weight
            name_probs += df_sorted["name_prob"].values * weight

        result_df["travel_prob"] = travel_probs
        result_df["name_prob"] = name_probs

        return result_df

    def calculate_labels_and_confidence(self, df: pd.DataFrame) -> pd.DataFrame:
        """è¨ˆç®—æ¨™ç±¤"""
        result_df = df.copy()

        # è¨ˆç®—æ¨™ç±¤
        result_df["label"] = (result_df["travel_prob"] > 0.5).astype(int)
        result_df["name_flg"] = (result_df["name_prob"] > 0.5).astype(int)

        return result_df

    def select_top_positive_samples(self, df: pd.DataFrame, top_k: int = 30000) -> tuple:
        """åˆ†åˆ¥æ ¹æ“šæ—…éŠå’Œå§“åæ©Ÿç‡é¸æ“‡å‰ K å€‹æ­£é¡æ¨£æœ¬"""
        
        # æ—…éŠåˆ†é¡ï¼šå…ˆç¯©é¸æ­£é¡ï¼Œå†æŒ‰æ©Ÿç‡æ’åº
        travel_positive = df[df["label"] == 1]
        if len(travel_positive) >= top_k:
            travel_top = travel_positive.nlargest(top_k, "travel_prob")
        else:
            # å¦‚æœæ­£é¡ä¸è¶³ï¼ŒæŒ‰æ©Ÿç‡æ’åºå–å‰ top_k
            travel_top = df.nlargest(top_k, "travel_prob")
            logger.warning(f"æ—…éŠæ­£é¡æ¨£æœ¬ä¸è¶³ {top_k} ç­†ï¼Œæ”¹ç‚ºæŒ‰æ©Ÿç‡å–å‰ {top_k} ç­†")
        
        # å§“ååˆ†é¡ï¼šå…ˆç¯©é¸æ­£é¡ï¼Œå†æŒ‰æ©Ÿç‡æ’åº
        name_positive = df[df["name_flg"] == 1]
        if len(name_positive) >= top_k:
            name_top = name_positive.nlargest(top_k, "name_prob")
        else:
            # å¦‚æœæ­£é¡ä¸è¶³ï¼ŒæŒ‰æ©Ÿç‡æ’åºå–å‰ top_k
            name_top = df.nlargest(top_k, "name_prob")
            logger.warning(f"å§“åæ­£é¡æ¨£æœ¬ä¸è¶³ {top_k} ç­†ï¼Œæ”¹ç‚ºæŒ‰æ©Ÿç‡å–å‰ {top_k} ç­†")

        # çµ±è¨ˆä¿¡æ¯
        logger.info(f"æ—…éŠåˆ†é¡ï¼šç¸½æ­£é¡ {len(travel_positive)} ç­†ï¼Œé¸æ“‡å‰ {len(travel_top)} ç­†")
        travel_selected_positive = (travel_top["label"] == 1).sum()
        logger.info(f"æ—…éŠåˆ†é¡é¸ä¸­æ¨£æœ¬ä¸­æ­£é¡: {travel_selected_positive} ({travel_selected_positive/len(travel_top)*100:.1f}%)")
        
        logger.info(f"å§“ååˆ†é¡ï¼šç¸½æ­£é¡ {len(name_positive)} ç­†ï¼Œé¸æ“‡å‰ {len(name_top)} ç­†")
        name_selected_positive = (name_top["name_flg"] == 1).sum()
        logger.info(f"å§“ååˆ†é¡é¸ä¸­æ¨£æœ¬ä¸­æ­£é¡: {name_selected_positive} ({name_selected_positive/len(name_top)*100:.1f}%)")

        return travel_top, name_top

    def run_ensemble(self, top_k: int = 30000) -> dict:
        """åŸ·è¡Œå®Œæ•´çš„é›†æˆæµç¨‹"""
        logger.info("é–‹å§‹åŸ·è¡Œå¤šæ¨¡å‹æŠ•ç¥¨é›†æˆ")

        # 1. è¼‰å…¥å€™é¸æª”æ¡ˆ
        dataframes = self.load_candidate_files()

        # 2. é©—è­‰ä¸€è‡´æ€§
        self.validate_consistency(dataframes)

        # 3. è¨ˆç®—åŠ æ¬Šå¹³å‡
        ensemble_df = self.weighted_average(dataframes)

        # 4. è¨ˆç®—æ¨™ç±¤å’Œä¿¡å¿ƒåº¦
        result_df = self.calculate_labels_and_confidence(ensemble_df)

        # 5. åˆ†åˆ¥é¸æ“‡å‰ K å€‹æ­£é¡æ¨£æœ¬
        travel_top, name_top = self.select_top_positive_samples(result_df, top_k)

        # 6. å„²å­˜çµæœ
        output_files = {}
        
        # 6.1 æ—…éŠåˆ†é¡çµæœï¼ˆç”¨æ–¼æäº¤ category.csvï¼‰
        category_file = self.output_dir / "category_result.csv"
        travel_top[["sms_id"]].to_csv(category_file, index=False)
        output_files["category"] = str(category_file)
        logger.info(f"æ—…éŠåˆ†é¡çµæœå·²å„²å­˜è‡³: {category_file}")

        # 6.2 å§“ååˆ†é¡çµæœï¼ˆç”¨æ–¼æäº¤ name.csvï¼‰
        name_file = self.output_dir / "name_result.csv"
        name_top[["sms_id"]].to_csv(name_file, index=False)
        output_files["name"] = str(name_file)
        logger.info(f"å§“ååˆ†é¡çµæœå·²å„²å­˜è‡³: {name_file}")

        logger.info(f"æ—…éŠåˆ†é¡è¼¸å‡ºæ¨£æœ¬æ•¸: {len(travel_top)}")
        logger.info(f"å§“ååˆ†é¡è¼¸å‡ºæ¨£æœ¬æ•¸: {len(name_top)}")

        return output_files


def main():
    """ä¸»å‡½æ•¸"""
    try:
        ensemble = VoteEnsemble()
        output_files = ensemble.run_ensemble()
        
        print(f"âœ… æŠ•ç¥¨é›†æˆå®Œæˆï¼")
        print(f"ğŸ“ æ—…éŠåˆ†é¡çµæœ: {output_files['category']}")
        print(f"ğŸ“ å§“ååˆ†é¡çµæœ: {output_files['name']}")

    except Exception as e:
        logger.error(f"åŸ·è¡Œå¤±æ•—: {str(e)}")
        raise


if __name__ == "__main__":
    main()
