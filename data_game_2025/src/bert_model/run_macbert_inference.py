#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MacBERT æ¨¡å‹æ¨è«–è…³æœ¬
å°ˆé–€ç”¨æ–¼é‹è¡Œ MacBERT æ¨¡å‹çš„æ¨è«–
"""

import sys
import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict

# æ·»åŠ  src ç›®éŒ„åˆ° Python è·¯å¾‘
src_dir = Path(__file__).parent.parent
sys.path.append(str(src_dir))

from bert_model.bert_config import BertConfig
from bert_model.bert_travel_inference import TravelBertInference
from bert_model.bert_name_inference import NameBertInference
from utils import load_input_csv


def save_dataframe_chunked(df, output_path: str, chunk_size: int = 10000) -> None:
    """
    åˆ†æ‰¹å„²å­˜ DataFrame ä»¥é¿å…è¨˜æ†¶é«”å•é¡Œ
    
    Args:
        df: è¦å„²å­˜çš„ DataFrame
        output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        chunk_size: æ¯æ‰¹çš„å¤§å°ï¼Œé è¨­ 10000
    """
    import pandas as pd
    
    total_rows = len(df)
    
    if total_rows <= chunk_size:
        # è³‡æ–™é‡å°ï¼Œç›´æ¥å„²å­˜
        df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"âœ… çµæœå·²ä¿å­˜: {output_path}")
    else:
        # è³‡æ–™é‡å¤§ï¼Œåˆ†æ‰¹å„²å­˜
        print(f"ğŸ”„ è³‡æ–™é‡è¼ƒå¤§ ({total_rows} ç­†)ï¼Œåˆ†æ‰¹å„²å­˜ä¸­...")
        for i in range(0, total_rows, chunk_size):
            chunk_end = min(i + chunk_size, total_rows)
            chunk_df = df.iloc[i:chunk_end]
            
            # ç¬¬ä¸€æ‰¹åŒ…å«è¡¨é ­ï¼Œå¾ŒçºŒæ‰¹æ¬¡ä¸åŒ…å«è¡¨é ­
            mode = 'w' if i == 0 else 'a'
            header = i == 0
            
            chunk_df.to_csv(output_path, mode=mode, header=header, index=False, encoding='utf-8')
            print(f"  ğŸ’¾ å·²å„²å­˜ç¬¬ {i//chunk_size + 1} æ‰¹ ({i+1}-{chunk_end}/{total_rows})")
        
        print(f"âœ… çµæœå·²åˆ†æ‰¹ä¿å­˜: {output_path}")


def infer_travel_classifier(
    model_dir: str,
    input_csv: str,
    batch_size: int = 32
) -> List[Dict]:
    """
    åŸ·è¡Œæ—…éŠåˆ†é¡æ¨è«–
    
    Args:
        model_dir: æ—…éŠåˆ†é¡æ¨¡å‹ç›®éŒ„
        input_csv: è¼¸å…¥ CSV æª”æ¡ˆè·¯å¾‘
        batch_size: æ‰¹æ¬¡å¤§å°
        
    Returns:
        é æ¸¬çµæœåˆ—è¡¨ï¼ŒåŒ…å« sms_id, travel_prob, label
    """
    print("=== BERT æ—…éŠç°¡è¨Šåˆ†é¡å™¨æ¨è«– ===")
    
    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼ˆå¦‚æœæ˜¯æœ¬åœ°è·¯å¾‘ï¼‰æˆ–æ˜¯å¦ç‚º Hugging Face æ¨¡å‹ ID
    is_local_path = os.path.exists(model_dir) or os.path.isabs(model_dir)
    is_hf_model = not is_local_path and "/" in model_dir
    
    if not is_local_path and not is_hf_model:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ—…éŠåˆ†é¡æ¨¡å‹: {model_dir}")
    
    # è¼‰å…¥æ¨è«–å™¨
    try:
        inferencer = TravelBertInference(model_dir)
        if is_hf_model:
            print(f"âœ… æ—…éŠåˆ†é¡æ¨¡å‹å¾ Hugging Face è¼‰å…¥æˆåŠŸ: {model_dir}")
        else:
            print(f"âœ… æ—…éŠåˆ†é¡æ¨¡å‹å¾æœ¬åœ°è¼‰å…¥æˆåŠŸ: {model_dir}")
    except Exception as e:
        raise Exception(f"è¼‰å…¥æ—…éŠåˆ†é¡æ¨¡å‹å¤±æ•—: {e}")
    
    # è¼‰å…¥è³‡æ–™
    try:
        messages = load_input_csv(input_csv)
        sms_ids = [msg['id'] for msg in messages]
        texts = [msg['message'] for msg in messages]
        print(f"âœ… è¼‰å…¥ {len(texts)} ç­†ç°¡è¨Š")
    except Exception as e:
        raise Exception(f"è¼‰å…¥è¼¸å…¥æª”æ¡ˆå¤±æ•—: {e}")
    
    # æ‰¹æ¬¡æ¨è«–
    try:
        print(f"ğŸ”„ é–‹å§‹æ—…éŠåˆ†é¡æ¨è«–ï¼ˆæ‰¹æ¬¡å¤§å°: {batch_size}ï¼‰...")
        labels, probabilities = inferencer.predict_batch(texts, batch_size=batch_size)
        print(f"âœ… æ—…éŠåˆ†é¡æ¨è«–å®Œæˆ")
    except Exception as e:
        raise Exception(f"æ—…éŠåˆ†é¡æ¨è«–å¤±æ•—: {e}")
    
    # æ•´ç†çµæœï¼Œæ©Ÿç‡ä¿ç•™åˆ°å°æ•¸é»ç¬¬4ä½ä»¥é¿å…éåº¦å››æ¨äº”å…¥
    results = []
    for sms_id, prob, label in zip(sms_ids, probabilities, labels):
        results.append({
            'sms_id': sms_id,
            'travel_prob': round(prob, 4),
            'label': label
        })
    return results


def infer_name_classifier(
    model_dir: str,
    input_csv: str,
    batch_size: int = 32
) -> List[Dict]:
    """
    åŸ·è¡Œå§“ååˆ†é¡æ¨è«–
    
    Args:
        model_dir: å§“ååˆ†é¡æ¨¡å‹ç›®éŒ„
        input_csv: è¼¸å…¥ CSV æª”æ¡ˆè·¯å¾‘
        batch_size: æ‰¹æ¬¡å¤§å°
        
    Returns:
        é æ¸¬çµæœåˆ—è¡¨ï¼ŒåŒ…å« sms_id, name_prob, name_flg
    """
    print("=== BERT å§“åç°¡è¨Šåˆ†é¡å™¨æ¨è«– ===")
    
    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼ˆå¦‚æœæ˜¯æœ¬åœ°è·¯å¾‘ï¼‰æˆ–æ˜¯å¦ç‚º Hugging Face æ¨¡å‹ ID
    is_local_path = os.path.exists(model_dir) or os.path.isabs(model_dir)
    is_hf_model = not is_local_path and "/" in model_dir
    
    if not is_local_path and not is_hf_model:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°å§“ååˆ†é¡æ¨¡å‹: {model_dir}")
    
    # è¼‰å…¥æ¨è«–å™¨
    try:
        inferencer = NameBertInference(model_dir)
        if is_hf_model:
            print(f"âœ… å§“ååˆ†é¡æ¨¡å‹å¾ Hugging Face è¼‰å…¥æˆåŠŸ: {model_dir}")
        else:
            print(f"âœ… å§“ååˆ†é¡æ¨¡å‹å¾æœ¬åœ°è¼‰å…¥æˆåŠŸ: {model_dir}")
    except Exception as e:
        raise Exception(f"è¼‰å…¥å§“ååˆ†é¡æ¨¡å‹å¤±æ•—: {e}")
    
    # è¼‰å…¥è³‡æ–™
    try:
        messages = load_input_csv(input_csv)
        sms_ids = [msg['id'] for msg in messages]
        texts = [msg['message'] for msg in messages]
        print(f"âœ… è¼‰å…¥ {len(texts)} ç­†ç°¡è¨Š")
    except Exception as e:
        raise Exception(f"è¼‰å…¥è¼¸å…¥æª”æ¡ˆå¤±æ•—: {e}")
    
    # æ‰¹æ¬¡æ¨è«–
    try:
        print(f"ğŸ”„ é–‹å§‹å§“ååˆ†é¡æ¨è«–ï¼ˆæ‰¹æ¬¡å¤§å°: {batch_size}ï¼‰...")
        labels, probabilities = inferencer.predict_batch(texts, batch_size=batch_size)
        print(f"âœ… å§“ååˆ†é¡æ¨è«–å®Œæˆ")
    except Exception as e:
        raise Exception(f"å§“ååˆ†é¡æ¨è«–å¤±æ•—: {e}")
    
    # æ•´ç†çµæœï¼Œæ©Ÿç‡ä¿ç•™åˆ°å°æ•¸é»ç¬¬4ä½ä»¥é¿å…éåº¦å››æ¨äº”å…¥
    results = []
    for sms_id, prob, label in zip(sms_ids, probabilities, labels):
        results.append({
            'sms_id': sms_id,
            'name_prob': round(prob, 4),
            'name_flg': label
        })
    return results


def combine_inference_results(
    travel_results: List[Dict],
    name_results: List[Dict],
    output_csv: str
) -> str:
    """
    åˆä½µæ—…éŠèˆ‡å§“ååˆ†é¡çµæœï¼Œä¸¦è¼¸å‡ºç‚º CSV
    ä½¿ç”¨è¨˜æ†¶é«”å‹å–„çš„æ–¹å¼è™•ç†å¤§é‡è³‡æ–™
    
    Args:
        travel_results: æ—…éŠåˆ†é¡çµæœ
        name_results: å§“ååˆ†é¡çµæœ
        output_csv: è¼¸å‡º CSV æª”æ¡ˆè·¯å¾‘
        
    Returns:
        è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    """
    import pandas as pd
    import gc
    
    print("=== åˆä½µæ¨è«–çµæœ ===")
    print(f"ğŸ”„ è™•ç†æ—…éŠè³‡æ–™: {len(travel_results)} ç­†")
    print(f"ğŸ”„ è™•ç†å§“åè³‡æ–™: {len(name_results)} ç­†")
    
    # åˆ†æ‰¹åˆä½µä»¥é¿å…è¨˜æ†¶é«”å•é¡Œ
    chunk_size = 10000
    total_batches = max(len(travel_results), len(name_results))
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    output_dir = os.path.dirname(output_csv)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    # å¦‚æœè³‡æ–™é‡è¼ƒå°ï¼Œä½¿ç”¨åŸæœ¬çš„æ–¹å¼
    if total_batches <= chunk_size:
        print("ğŸ“¦ è³‡æ–™é‡è¼ƒå°ï¼Œä½¿ç”¨æ¨™æº–åˆä½µæ–¹å¼")
        
        # å°‡çµæœè½‰æ›ç‚º DataFrame
        travel_df = pd.DataFrame(travel_results)
        name_df = pd.DataFrame(name_results)
        
        # åˆä½µçµæœï¼ˆä»¥ sms_id ç‚ºéµï¼‰
        merged_df = pd.merge(
            travel_df,
            name_df,
            on='sms_id',
            how='outer'
        )
        print(f"âœ… å·²åˆä½µçµæœ")
        
        # ç¢ºä¿æ¬„ä½é †åºç¬¦åˆ PRD è¦æ±‚: sms_id, travel_prob, label, name_prob, name_flg
        result_df = merged_df[['sms_id', 'travel_prob', 'label', 'name_prob', 'name_flg']]
        print(f"âœ… å·²ç¢ºä¿æ¬„ä½é †åºç¬¦åˆ PRD è¦æ±‚")

        # ä¿®æ­£SMS IDæ’åºå•é¡Œï¼šå°‡sms_idè½‰æ›ç‚ºæ•´æ•¸å¾Œæ’åº
        try:
            result_df['sms_id'] = pd.to_numeric(result_df['sms_id'], errors='coerce')
            result_df = result_df.sort_values('sms_id').reset_index(drop=True)
            print(f"âœ… å·²æŒ‰SMS IDæ•´æ•¸é †åºæ’åº")
        except Exception as e:
            print(f"âš ï¸ SMS IDæ’åºè­¦å‘Š: {e}")
        
        # ä½¿ç”¨åˆ†æ‰¹å„²å­˜å‡½æ•¸
        save_dataframe_chunked(result_df, output_csv)
        
        # æ¸…ç†è¨˜æ†¶é«”
        del travel_df, name_df, merged_df, result_df
        gc.collect()
        
    else:
        print(f"ğŸ“¦ è³‡æ–™é‡è¼ƒå¤§ï¼Œä½¿ç”¨åˆ†æ‰¹åˆä½µæ–¹å¼ï¼ˆæ¯æ‰¹ {chunk_size} ç­†ï¼‰")
        
        # å»ºç«‹ sms_id åˆ°ç´¢å¼•çš„æ˜ å°„ä»¥åŠ é€ŸæŸ¥æ‰¾
        print("ğŸ”„ å»ºç«‹ç´¢å¼•æ˜ å°„...")
        travel_dict = {item['sms_id']: item for item in travel_results}
        name_dict = {item['sms_id']: item for item in name_results}
        
        # ç²å–æ‰€æœ‰ sms_id ä¸¦æ’åº
        all_sms_ids = set(travel_dict.keys()) | set(name_dict.keys())
        print(f"ğŸ“Š ç¸½å…±æœ‰ {len(all_sms_ids)} å€‹å”¯ä¸€çš„ SMS ID")
        
        # å°‡ sms_id è½‰æ›ç‚ºæ•¸å­—ä¸¦æ’åº
        try:
            sorted_sms_ids = sorted(all_sms_ids, key=lambda x: int(x))
            print("âœ… SMS ID å·²æŒ‰æ•¸å­—é †åºæ’åº")
        except (ValueError, TypeError):
            sorted_sms_ids = sorted(all_sms_ids)
            print("âš ï¸ SMS ID ç„¡æ³•è½‰æ›ç‚ºæ•¸å­—ï¼Œä½¿ç”¨å­—ä¸²æ’åº")
        
        # åˆ†æ‰¹è™•ç†ä¸¦ç›´æ¥å¯«å…¥æª”æ¡ˆ
        first_batch = True
        total_processed = 0
        
        for i in range(0, len(sorted_sms_ids), chunk_size):
            batch_sms_ids = sorted_sms_ids[i:i + chunk_size]
            batch_results = []
            
            for sms_id in batch_sms_ids:
                # å¾å…©å€‹å­—å…¸ä¸­ç²å–è³‡æ–™
                travel_data = travel_dict.get(sms_id, {})
                name_data = name_dict.get(sms_id, {})
                
                # åˆä½µè³‡æ–™
                combined_row = {
                    'sms_id': sms_id,
                    'travel_prob': travel_data.get('travel_prob', 0.0),
                    'label': travel_data.get('label', 0),
                    'name_prob': name_data.get('name_prob', 0.0),
                    'name_flg': name_data.get('name_flg', 0)
                }
                batch_results.append(combined_row)
            
            # å°‡æ‰¹æ¬¡çµæœè½‰æ›ç‚º DataFrame ä¸¦å¯«å…¥
            batch_df = pd.DataFrame(batch_results)
            
            # å¯«å…¥æª”æ¡ˆ
            mode = 'w' if first_batch else 'a'
            header = first_batch
            
            batch_df.to_csv(output_csv, mode=mode, header=header, index=False, encoding='utf-8')
            
            total_processed += len(batch_results)
            batch_num = (i // chunk_size) + 1
            total_batches_calc = (len(sorted_sms_ids) + chunk_size - 1) // chunk_size
            
            print(f"  ï¿½ å·²è™•ç†ç¬¬ {batch_num}/{total_batches_calc} æ‰¹ ({total_processed}/{len(sorted_sms_ids)})")
            
            # æ¸…ç†è¨˜æ†¶é«”
            del batch_df, batch_results
            gc.collect()
            
            first_batch = False
        
        print(f"âœ… åˆ†æ‰¹åˆä½µå®Œæˆï¼Œç¸½å…±è™•ç† {total_processed} ç­†è³‡æ–™")
        
        # æ¸…ç†è¨˜æ†¶é«”
        del travel_dict, name_dict, all_sms_ids, sorted_sms_ids
        gc.collect()
    
    print(f"ğŸ“Š ç¸½å…±è™•ç† {len(travel_results)} ç­†ç°¡è¨Š")
    
    # è¨ˆç®—çµ±è¨ˆæ•¸æ“šï¼ˆé¿å…é‡æ–°è¼‰å…¥æ•´å€‹æª”æ¡ˆï¼‰
    travel_positive = sum(1 for r in travel_results if r.get('label', 0) == 1)
    name_positive = sum(1 for r in name_results if r.get('name_flg', 0) == 1)
    
    print(f"ğŸ“Š æ—…éŠç›¸é—œç°¡è¨Š: {travel_positive} ç­†")
    print(f"ğŸ“Š å§“åç›¸é—œç°¡è¨Š: {name_positive} ç­†")
    print(f"âœ… åˆä½µçµæœå·²ä¿å­˜: {output_csv}")
    
    return output_csv


def run_macbert_inference(input_file=None, output_dir=None, travel_model=None, name_model=None, mode='both'):
    """
    åŸ·è¡Œ MacBERT æ¨¡å‹æ¨è«–
    
    Args:
        input_file: è¼¸å…¥ CSV æª”æ¡ˆè·¯å¾‘
        output_dir: è¼¸å‡ºç›®éŒ„è·¯å¾‘
        travel_model: æ—…éŠåˆ†é¡æ¨¡å‹è·¯å¾‘æˆ– Hugging Face æ¨¡å‹ ID
        name_model: å§“ååˆ†é¡æ¨¡å‹è·¯å¾‘æˆ– Hugging Face æ¨¡å‹ ID
        mode: æ¨è«–æ¨¡å¼ ('travel', 'name', 'both')
    """
    print("ğŸš€ é–‹å§‹åŸ·è¡Œ MacBERT æ¨¡å‹æ¨è«–...")
    
    # ä½¿ç”¨ MacBERT å°ˆç”¨é…ç½®ï¼Œä¸¦è™•ç†é…ç½®æª”æ¡ˆè¼‰å…¥éŒ¯èª¤
    try:
        config_path = os.path.join(os.path.dirname(__file__), "config_macbert.ini")
        config = BertConfig(config_path)
        inference_config = config.get_inference_config()
        
        print(f"ğŸ“‹ æˆåŠŸè¼‰å…¥ MacBERT é…ç½®æª”æ¡ˆ: {config_path}")
        print(f"ğŸ“¦ MacBERT é…ç½®çš„æ‰¹æ¬¡å¤§å°: {inference_config['inference_batch_size']}")
        
        # ç›´æ¥å¾é…ç½®æª”æ¡ˆè®€å– output_dirï¼ˆåœ¨ inference å€æ®µï¼‰
        config_output_dir = config.config.get('inference', 'output_dir')
        
    except Exception as e:
        print(f"âš ï¸ MacBERT é…ç½®æª”æ¡ˆè¼‰å…¥å¤±æ•—: {e}")
        print("ğŸ”„ ä½¿ç”¨ MacBERT é è¨­é…ç½®...")
        # ä½¿ç”¨é è¨­é…ç½®
        inference_config = {
            'input_file': '/Users/winstontang/PycharmProjects/forensic/data_game_2025/data/raw/datagame_sms_stage1_raw_TEXT_ONLY.csv',
            'inference_batch_size': 32,  # MacBERT é è¨­è¼ƒå°çš„æ‰¹æ¬¡å¤§å°
        }
        config_output_dir = '/Users/winstontang/PycharmProjects/forensic/data_game_2025/data/results/vote/candidates'
    
    # è¨­å®šè¼¸å…¥æª”æ¡ˆ
    if input_file is None:
        input_file = inference_config['input_file']
    
    # è¨­å®šè¼¸å‡ºç›®éŒ„
    if output_dir is None:
        output_dir = Path(config_output_dir)
    else:
        output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è™•ç†æ¨¡å‹è·¯å¾‘
    def get_model_path(model_arg, model_type):
        """ç²å–æ¨¡å‹è·¯å¾‘ï¼Œæ”¯æ´æœ¬åœ°è·¯å¾‘å’Œ Hugging Face æ¨¡å‹ ID"""
        if model_arg:
            # ç”¨æˆ¶æŒ‡å®šäº†æ¨¡å‹
            is_local_path = os.path.exists(model_arg) or os.path.isabs(model_arg)
            is_hf_model = not is_local_path and "/" in model_arg
            
            if is_local_path or is_hf_model:
                return model_arg
            else:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°{model_type}åˆ†é¡æ¨¡å‹: {model_arg}")
        else:
            # ä½¿ç”¨é è¨­é‚è¼¯æœç´¢æœ¬åœ° MacBERT æ¨¡å‹
            base_dir = Path("/Users/winstontang/PycharmProjects/forensic/data_game_2025/results")
            models = list(base_dir.glob(f"{model_type}_macbert_macbert_*"))
            
            if not models:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°æœ¬åœ° MacBERT {model_type}åˆ†é¡æ¨¡å‹ï¼Œè«‹å…ˆè¨“ç·´æ¨¡å‹æˆ–æŒ‡å®š Hugging Face æ¨¡å‹ IDï¼")
            
            # é¸æ“‡æœ€æ–°çš„æ¨¡å‹
            return str(max(models, key=lambda x: x.stat().st_mtime))
    
    results = {}
    
    # è™•ç†æ—…éŠåˆ†é¡
    if mode in ['travel', 'both']:
        travel_model_path = get_model_path(travel_model, 'travel')
        print(f"ğŸ“ æ—…éŠåˆ†é¡æ¨¡å‹: {travel_model_path}")
        
        print("\nğŸ” é–‹å§‹æ—…éŠåˆ†é¡æ¨è«–...")
        travel_results = infer_travel_classifier(
            model_dir=travel_model_path,
            input_csv=input_file,
            batch_size=inference_config['inference_batch_size']
        )
        results['travel'] = travel_results
    
    # è™•ç†å§“ååˆ†é¡
    if mode in ['name', 'both']:
        name_model_path = get_model_path(name_model, 'name')
        print(f"ğŸ“ å§“ååˆ†é¡æ¨¡å‹: {name_model_path}")
        
        print("\nğŸ” é–‹å§‹å§“ååˆ†é¡æ¨è«–...")
        name_results = infer_name_classifier(
            model_dir=name_model_path,
            input_csv=input_file,
            batch_size=inference_config['inference_batch_size']
        )
        results['name'] = name_results
    
    # ç”Ÿæˆæ™‚é–“æˆ³è¨˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    
    # åˆä½µçµæœï¼ˆå¦‚æœå…©ç¨®åˆ†é¡éƒ½åŸ·è¡Œäº†ï¼‰
    if mode == 'both' and 'travel' in results and 'name' in results:
        print("\nğŸ”„ åˆä½µæ¨è«–çµæœ...")
        combined_output = str(output_dir / f"both_macbert_{timestamp}.csv")
        combine_inference_results(results['travel'], results['name'], combined_output)
        print(f"âœ… åˆä½µçµæœå®Œæˆ: {combined_output}")
        results['combined'] = combined_output
    elif mode == 'travel' and 'travel' in results:
        # åªæœ‰æ—…éŠåˆ†é¡ï¼Œç›´æ¥è¼¸å‡ºï¼ˆæ”¯æ´åˆ†æ‰¹å„²å­˜ï¼‰
        import pandas as pd
        print("\nğŸ”„ å„²å­˜æ—…éŠåˆ†é¡çµæœ...")
        travel_output = str(output_dir / f"travel_macbert_{timestamp}.csv")
        travel_df = pd.DataFrame(results['travel'])
        save_dataframe_chunked(travel_df, travel_output)
        results['travel_output'] = travel_output
        print(f"âœ… æ—…éŠåˆ†é¡çµæœå®Œæˆ: {travel_output}")
    elif mode == 'name' and 'name' in results:
        # åªæœ‰å§“ååˆ†é¡ï¼Œç›´æ¥è¼¸å‡ºï¼ˆæ”¯æ´åˆ†æ‰¹å„²å­˜ï¼‰
        import pandas as pd
        print("\nğŸ”„ å„²å­˜å§“ååˆ†é¡çµæœ...")
        name_output = str(output_dir / f"name_macbert_{timestamp}.csv")
        name_df = pd.DataFrame(results['name'])
        save_dataframe_chunked(name_df, name_output)
        results['name_output'] = name_output
        print(f"âœ… å§“ååˆ†é¡çµæœå®Œæˆ: {name_output}")
    
    print("\nğŸ‰ MacBERT æ¨è«–å®Œæˆï¼")
    
    # æ§‹å»ºè¿”å›çµæœ
    return_results = {}
    if 'travel' in results:
        return_results['travel'] = f"æ—…éŠåˆ†é¡å®Œæˆï¼Œå…± {len(results['travel'])} ç­†è³‡æ–™"
    if 'name' in results:
        return_results['name'] = f"å§“ååˆ†é¡å®Œæˆï¼Œå…± {len(results['name'])} ç­†è³‡æ–™"
    if 'combined' in results:
        return_results['combined'] = results['combined']
    if 'travel_output' in results:
        return_results['travel_output'] = results['travel_output']
    if 'name_output' in results:
        return_results['name_output'] = results['name_output']
    
    return return_results


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="MacBERT æ¨¡å‹æ¨è«–")
    parser.add_argument('--input', help='è¼¸å…¥ CSV æª”æ¡ˆè·¯å¾‘ (å¯é¸ï¼Œä½¿ç”¨é…ç½®æª”æ¡ˆä¸­çš„é è¨­å€¼)')
    parser.add_argument('--output-dir', help='è¼¸å‡ºç›®éŒ„è·¯å¾‘ (å¯é¸)')
    parser.add_argument('--travel-model', help='æ—…éŠåˆ†é¡æ¨¡å‹è·¯å¾‘æˆ– Hugging Face æ¨¡å‹ ID')
    parser.add_argument('--name-model', help='å§“ååˆ†é¡æ¨¡å‹è·¯å¾‘æˆ– Hugging Face æ¨¡å‹ ID')
    parser.add_argument('--mode', choices=['travel', 'name', 'both'], default='both',
                       help='æ¨è«–æ¨¡å¼: travelï¼ˆæ—…éŠï¼‰, nameï¼ˆå§“åï¼‰, æˆ– bothï¼ˆå…©è€…ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸ”¥ MacBERT æ¨è«–è…³æœ¬")
    print("=" * 40)
    
    # é¡¯ç¤ºé…ç½®è³‡è¨Š
    print("ğŸ”§ è¼‰å…¥ MacBERT é…ç½®...")
    
    # åŸ·è¡Œæ¨è«–
    results = run_macbert_inference(
        input_file=args.input,
        output_dir=args.output_dir,
        travel_model=args.travel_model,
        name_model=args.name_model,
        mode=args.mode
    )
    
    print("\nğŸ“‹ æ¨è«–çµæœç¸½çµ:")
    for task, path in results.items():
        print(f"  {task}: {path}")
    
    print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
    print("1. æ¨è«–çµæœå·²ä¿å­˜åœ¨ candidates ç›®éŒ„")
    print("2. å¯ä»¥ç”¨æ–¼å¾ŒçºŒçš„æ¨¡å‹æ¯”è¼ƒåˆ†æ")
    print("3. combined æª”æ¡ˆåŒ…å«å®Œæ•´çš„åˆ†é¡çµæœ")


if __name__ == "__main__":
    main()
